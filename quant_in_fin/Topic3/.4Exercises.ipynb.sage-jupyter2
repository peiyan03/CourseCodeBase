{"backend_state":"init","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-4fedd7e4-4073-49b1-988a-a2e8bb180a80.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"last_backend_state":1761231945786,"last_ipynb_save":1761231945840,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1761091146532,"exec_count":3,"id":"cb33ae","input":"from grading_tools import *","kernel":"python3","last":81,"no_halt":true,"pos":0,"start":1761091146504,"state":"done","type":"cell"}
{"cell_type":"code","end":1761091148387,"exec_count":4,"id":"c17151","input":"import numpy as np\nimport matplotlib.pyplot as plt\n\nSigma = np.array([[3, 1], [1, 2]])\n\nL = np.linalg.cholesky(Sigma)\n\nX = np.random.randn(2,100000)\n\n# Y = L X + μ with μ = 0\nmu = np.zeros((2,1))\nY = (L@X) + mu\n\nsample = Y\n\nplt.figure(figsize=(6,6))\nplt.scatter(Y[0, :10000], Y[1, :10000], s=4, alpha=0.5, color='steelblue') \n\nplt.title('Samples from $\\\\mathcal{N}(0, \\\\Sigma)$ using Cholesky decomposition')\nplt.xlabel('$Y_1$')\nplt.ylabel('$Y_2$')\nplt.axis('equal')  \nplt.grid(True)\nplt.show()","kernel":"python3","last":626,"metadata":{"deletable":false,"jupyter":{},"nbgrader":{"cell_type":"code","checksum":"fd775fe0c8d3db674e1cce401ff7517a","grade":false,"grade_id":"c17151","locked":false,"schema_version":3,"solution":true,"task":false}},"no_halt":true,"output":{"0":{"data":{"image/png":"9af1d83e1350d7343d64bc114c0ce2d916aa9c20","text/plain":"<Figure size 432x432 with 1 Axes>"},"metadata":{"image/png":{"height":388,"width":385},"needs_background":"light"}}},"pos":3,"start":1761091146580,"state":"done","type":"cell"}
{"cell_type":"code","end":1761091148450,"exec_count":5,"id":"b42e0d","input":"expected = np.array( [[3,1],[1,2]] )\nassert sample.shape==(2,100000), \"Wrong size sample\"\nassert np.mean(sample[0,:])<0.05\nassert np.mean(sample[1,:])<0.05\nactual = np.cov(sample, rowvar=True)\nassert np.linalg.norm( actual - expected )<0.1\nauto_marking_message()","kernel":"python3","last":27,"metadata":{"deletable":false,"editable":false,"jupyter":{},"nbgrader":{"cell_type":"code","checksum":"1d7798ddd10d1a535cd4395a59edd141","grade":true,"grade_id":"b42e0d","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"no_halt":true,"output":{"0":{"name":"stdout","text":"Auto marking message: ✔️ Correct\n"}},"pos":4,"start":1761091148410,"state":"done","type":"cell"}
{"cell_type":"code","end":1761091148554,"exec_count":6,"id":"8e6ce9","input":"import numpy as np\nfrom math import *\n\ndef my_chol( rho ):\n    if not (-1 < rho < 1): \n        raise ValueError(\"Matrix is not positive-definite unless |rho| < 1.\")\n    else:\n        Sigma = np.array([[1,0],[rho,np.sqrt(1.0 - rho**2)]])\n        return Sigma\n    ","kernel":"python3","last":18,"metadata":{"deletable":false,"jupyter":{},"nbgrader":{"cell_type":"code","checksum":"0e4aff69955b8d52d34b4b276dec713c","grade":false,"grade_id":"8e6ce9","locked":false,"schema_version":3,"solution":true,"task":false}},"no_halt":true,"pos":6,"start":1761091148474,"state":"done","type":"cell"}
{"cell_type":"code","end":1761091148677,"exec_count":7,"id":"c9cffe","input":"rho = 0.6\nL = my_chol( rho )\nassert L[0,1]==0, \"Must be lower triangular\"\nassert L[0,0]>0, \"Must have a positive diagonal\"\nassert L[1,1]>0, \"Must have a positive diagonal\"\nassert np.linalg.norm(L @ L.transpose()-np.array([[1,rho],[rho,1]]))<0.0001","kernel":"python3","last":20,"metadata":{"deletable":false,"editable":false,"jupyter":{},"nbgrader":{"cell_type":"code","checksum":"518bf98beb4bcf065fa83f195da88dd7","grade":true,"grade_id":"c9cffe","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"no_halt":true,"pos":7,"start":1761091148653,"state":"done","type":"cell"}
{"cell_type":"code","end":1761091455433,"exec_count":14,"id":"abbaea","input":"def find_5_pseudo_square_roots( rho ):\n    s = np.sqrt(1 - rho**2)\n    # Lower-triangular roots\n    H1 = np.array([[1, 0], [rho, s]])\n    H2 = np.array([[1, 0], [rho, -s]])\n    H3 = np.array([[-1, 0], [-rho, s]])\n    H4 = np.array([[-1, 0], [-rho, -s]])\n    \n    # Upper-triangular root\n    H5 = np.array([[ s,  rho],[ 0.,  1.]])\n    \n    return [H1, H2, H3, H4, H5]   \n\nrho = 0.3\nroots = find_5_pseudo_square_roots( 0.3 )\nsquare = np.array([[1,rho],[rho,1]])\nassert len(roots)==5\nd = {}\nfor i in range(0,5):\n    r = roots[i]\n    key = str(roots[i])\n    d[key] = i\n    print(np.linalg.norm(r @ r.transpose() - square))","kernel":"python3","last":169,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"392a7e30fc8db7e3014d7ad67e822cf7","grade":false,"grade_id":"abbaea","locked":false,"schema_version":3,"solution":true,"task":false}},"output":{"0":{"name":"stdout","text":"0.0\n0.0\n0.0\n0.0\n0.0\n"}},"pos":9,"slide":"skip","start":1761091455361,"state":"done","type":"cell"}
{"cell_type":"code","end":1761091456864,"exec_count":15,"id":"04ee6c","input":"rho = 0.3\nroots = find_5_pseudo_square_roots( 0.3 )\nsquare = np.array([[1,rho],[rho,1]])\nassert len(roots)==5\nd = {}\nfor i in range(0,5):\n    r = roots[i]\n    key = str(roots[i])\n    d[key] = i\n    assert (np.linalg.norm(r @ r.transpose() - square))<0.000001\nfor i in range(0,4):    \n    assert abs(roots[i][0,1])<0.000001\nassert abs(roots[4][1,0])<0.000001\nassert len(d)==5\nauto_marking_message()","kernel":"python3","last":184,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"66b681bcfdd085cc5652ffb72eba95be","grade":true,"grade_id":"04ee6c","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","text":"Auto marking message: ✔️ Correct\n"}},"pos":10,"slide":"skip","start":1761091456837,"state":"done","type":"cell"}
{"cell_type":"code","end":1761091779474,"exec_count":16,"id":"77f0c1","input":"Sigma = [\n    [9,1,1],\n    [1,2,3],\n    [1,3,5]\n]\n\nL = np.linalg.cholesky(Sigma)\nprint(L)","kernel":"python3","output":{"0":{"name":"stdout","text":"[[3.         0.         0.        ]\n [0.33333333 1.37436854 0.        ]\n [0.33333333 2.10197542 0.68599434]]\n"}},"pos":11.25,"start":1761091779445,"state":"done","type":"cell"}
{"cell_type":"code","end":1761092347952,"exec_count":19,"id":"b373d8","input":"def cholesky(s):\n    Sigma = np.asarray(s, dtype=float)\n    n = Sigma.shape[0]\n    L = np.zeros_like(Sigma)\n\n    for j in range(n):\n        # diagonal\n        s_jj = Sigma[j, j]\n        tmp = s_jj - np.dot(L[j, :j], L[j, :j])\n        if tmp <= 0.00000001:\n            raise np.linalg.LinAlgError(\"Matrix is not positive definite (or ill-conditioned).\")\n        L[j, j] = np.sqrt(tmp)\n\n        # below-diagonal column j\n        for i in range(j+1, n):\n            s_ij = Sigma[i, j]\n            tmp = s_ij - np.dot(L[i, :j], L[j, :j])\n            L[i, j] = tmp / L[j, j]\n\n    return L","kernel":"python3","metadata":{"deletable":false,"jupyter":{},"nbgrader":{"cell_type":"code","checksum":"27c3a3dcb5e9f29085884e6b43e0d91b","grade":false,"grade_id":"b373d8","locked":false,"schema_version":3,"solution":true,"task":false}},"pos":13,"slide":"skip","start":1761092347851,"state":"done","type":"cell"}
{"cell_type":"code","end":1761092349308,"exec_count":20,"id":"e36683","input":"rho = 0.6\nL = cholesky( np.array([[1,rho],[rho,1]]) )\nassert L[0,1]==0, \"Must be lower triangular\"\nassert L[0,0]>0, \"Must have a positive diagonal\"\nassert L[1,1]>0, \"Must have a positive diagonal\"\nassert np.linalg.norm(L @ L.transpose()-np.array([[1,rho],[rho,1]]))<0.0001\nL = np.array([[1,0,0],[2,3,0],[4,5,6]])\nS = L @ L.transpose()\nassert np.linalg.norm( cholesky(S)-L )<0.0001\nauto_marking_message()","kernel":"python3","last":27,"metadata":{"deletable":false,"editable":false,"jupyter":{},"nbgrader":{"cell_type":"code","checksum":"15ce241a89cdfd3288a44814f9f5b45a","grade":true,"grade_id":"e36683","locked":true,"points":1,"schema_version":3,"solution":false,"task":false}},"output":{"0":{"name":"stdout","text":"Auto marking message: 😀 Correct\n"}},"pos":14,"slide":"skip","start":1761092349283,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"1715b8","input":"## Exercise\n\nYou can compute the Cholesky decomposition of a matrix using the Python function `numpy.linalg.cholesky`. Use this to compute\nthe Cholesky decomposition of \n$$\n\\Sigma = \\left( \\begin{array}{cc}\n3 & 1 \\\\\n1 & 2\n\\end{array}\n\\right)\n$$ \nand check your answer.\n\nUse the Cholesky decomposition of $\\Sigma$  to draw a scatter plot of the multivariate normal distribution with mean $0$ and covariance matrix $\\Sigma$.\n\nTo check your answer using the automated tests, create a $2 \\times 100000$ matrix whose columns contain $100000$ samples from such a distribution and call this matrix `sample`.\n\n","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"25073f","input":"## Exercise\n\nCompute the Cholesky decomposition of the matrix\n$$\n\\Sigma = \\left( \\begin{array}{cc}\n1 & \\rho \\\\\n\\rho & 1\n\\end{array}\n\\right)$$\nanalytically. Write a function `my_chol` which takes a single parameter `rho` and returns the Cholesky decomposition of\nthis matrix computed using your formula.\n\nWhat condition do you need on $\\rho$ for this matrix to be positive-definite?\n\n","pos":5,"type":"cell"}
{"cell_type":"markdown","id":"4dbb36","input":"## Exercise\n\nShow that pseudo square roots are far from unique by finding 4 lower triangular pseudo square roots of the matrix\n$$\n\\Sigma = \\left( \\begin{array}{cc}\n1 & \\rho \\\\\n\\rho & 1\n\\end{array}\n\\right)$$\nand one upper triangular pseudo square root.\n\nWrite a function `find_5_pseudo_square_roots` which returns a list\nof the 5 roots you have found, starting with the lower traingular roots.","pos":8,"slide":"skip","type":"cell"}
{"cell_type":"markdown","id":"742290","input":"## Exercise\n\nImplement your own `cholesky` function using the following formulae:\n\n$$ \\ell_{jj} = \\sqrt{ s_{jj} - \\sum_{k=1}^{j-1} \\ell_{jk}^2 } $$\n\nand\n$$ \\ell_{ij} = \\frac{1}{\\ell_{jj}} \\left( s_{i j} - \\sum_{k=1}^{j-1} \\ell_{ik} \\ell_{jk} \\right)$$\nif $i>j$, where $\\ell_{ij}$ are the components of $L$ and $s_{ij}$ are the components of $\\Sigma$ and $L$ is the Cholesky decomposition of the positive definite symmetric matrix $\\Sigma$.\n\nNote that this formula has been written using\nthe mathematics convention that indices start at $1$. To change to the maths convention simply change the term $k=1$ to $k=0$\nand the formulae will still hold.\n\n","pos":12,"slide":"skip","type":"cell"}
{"cell_type":"markdown","id":"cf5ce0","input":"","pos":11.5,"type":"cell"}
{"cell_type":"markdown","id":"e3eba7","input":"# Exercises","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"ead3d2","input":"## Exercise\n\nCompute the Cholesky decomposition of the matrix \n$$\n\\left( \\begin{array}{ccc}\n9 & 1 & 1 \\\\\n1 & 2 & 3 \\\\\n1 & 3 & 5\n\\end{array}\n\\right)\n$$by hand and check your answer using  the Python function `numpy.linalg.cholesky`. \n\n","pos":11,"type":"cell"}
{"cell_type":"markdown","id":"ebe477","input":"## Further Reading \\- not examinable\n\nWe now give a complete proof of the existence of the Cholesky decomposition of a positive\\-definite symmetric matrix $\\Sigma$. In the lecture we missed the following:\n\n* The argument in the lectures is very vague saying \"continuing in this way\" rather than giving a fully rigorous induction proof.\n\n* The argument in the lectures failed to check that all the square roots are of non\\-negative quantities.\n\n**Proof:**\n\nSuppose as an induction hypothesis that the result is true for $(n-1) \\times (n-1)$ matrices.\nWe write $\\Sigma$ in block diagonal form as\n$$\n\\Sigma = \n\\left( \\begin{array}{c|c}\n\\Sigma_{n-1} & v_{n-1} \\\\ \\hline\nv_{n-1}^T & s\n\\end{array}\n\\right)\n$$\nwhere $\\Sigma_{n-1}$ is an $(n-1)\\times(n-1)$ symmetric matrix, $v_{n-1}$ is a vector\nof length $(n-1)$ and $s$ is a scalar.\n\nWe now define $L$ by\n$$\nL = \n\\left( \n\\begin{array}{c|c}\nL_{n-1} & 0 \\\\ \\hline\nw_{n-1}^T & w\n\\end{array}\n\\right)\n$$\n\nwhere $w_{n-1}$ is some $n$ vector to be determined, and $w$ is a scalar\nto be determined. We require that $L_{n-1}$ is lower triangular with positive diagonal and that\n$$\nL L^T = \\Sigma.\n$$\nThis last condition is equivalent to the three conditions\n\\begin{equation}\nL_{n-1} L_{n-1}^T = \\Sigma_{n-1}, \n\\end{equation}\n\\begin{equation}\nL_{n-1} w_{n-1}= v_{n-1}\n\\qquad (1)\n\\end{equation}\nand\n\\begin{equation}\nw_{n-1}^T w_{n-1} + w^2 = s.\n\\end{equation}\nIt is easy to check that $S_{n-1}$ is positive definite. So there is a unique\nchoice for $L_{n-1}$ by our induction hypothesis.\n\nSince $L_{n-1}$ is lower triangular with positive diagonal, it has a non-zero\ndeterminant and so is invertible. Hence there is a unique $w_{n-1}$ solving\n(1). (Indeed this equation will already be in echelon form so it is quick and easy to solve). We now require that:\n$$\nw^2 = s - w_{n-1}^T w_{n-1}.\n$$\nThere will be a unique positive solution to this equation if and only if\n$$\ns - w_{n-1}^T w_{n-1} > 0.\n$$\nTo see that this inequality will hold, we define a vector $v$ in block diagonal\nform by:\n$$\nv = \\left(\n\\begin{array}{c}\n-(L_{n-1}^T)^{-1} w_{n-1} \\\\ \\hline\n1\n\\end{array}\n\\right)\n$$\nwe know that $v^T \\Sigma v > 0$ as $\\Sigma$ is positive definite. We compute\n\n$$\n\\begin{split}\nv^T \\Sigma v &= \\left(\n\\begin{array}{c|c}\n-w_{n-1} (L_{n-1})^{-1}  & 1\n\\end{array}\n\\right)\n\\left( \\begin{array}{c|c}\n\\Sigma_{n-1} & v_{n-1} \\\\ \\hline\nv_{n-1}^T & s\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{c}\n-(L_{n-1}^T)^{-1} w_{n-1} \\\\ \\hline\n1\n\\end{array}\n\\right) \\\\\n&= \\left(\n\\begin{array}{c|c}\n-w_{n-1} (L_{n-1})^{-1}  & 1\n\\end{array}\n\\right)\n\\left( \\begin{array}{c|c}\nL_{n-1} L_{n-1}^T & L_{n-1} w_{n-1} \\\\ \\hline\nw_{n-1}^T L_{n-1}^T & s\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{c}\n-(L_{n-1}^T)^{-1} w_{n-1} \\\\ \\hline\n1\n\\end{array}\n\\right) \\\\\n&= \\left(\n\\begin{array}{c|c}\n-w_{n-1} (L_{n-1})^{-1}  & 1\n\\end{array}\n\\right)\n\\left( \\begin{array}{c}\n-L_{n-1} w_{n-1} + L_{n-1} w_{n-1} \\\\ \\hline\n- w_{n-1}^T w_{n-1} + s\n\\end{array}\n\\right) \\\\\n&=\n\\left(\n\\begin{array}{c|c}\n-w_{n-1} (L_{n-1})^{-1}  & 1\n\\end{array}\n\\right)\n\\left( \\begin{array}{c}\n0 \\\\ \\hline\n- w_{n-1}^T w_{n-1} + s\n\\end{array}\n\\right) \\\\\n&= s - w_{n-1}^T w_{n-1}.\n\\end{split}\n$$\n\nThis quantity is positive, as required, so there is a unique positive solution for $w$. $\\quad \\square$\n\n","pos":15,"slide":"notes","type":"cell"}
{"id":0,"time":1761231912173,"type":"user"}
{"last_load":1760895553309,"type":"file"}